{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T09:59:12.410559Z",
     "iopub.status.busy": "2024-09-20T09:59:12.410180Z",
     "iopub.status.idle": "2024-09-20T09:59:12.787194Z",
     "shell.execute_reply": "2024-09-20T09:59:12.786260Z",
     "shell.execute_reply.started": "2024-09-20T09:59:12.410521Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython\n",
    "from IPython.display import Audio\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import get_models_dir, get_processed_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_csv_path = get_processed_data_dir(\"speech_sentiment\") / \"emotion_dataset.csv\"\n",
    "data = pd.read_csv(emotion_csv_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_emotions = data.emotion.unique()\n",
    "EMOTIONS = {i: emotion for i, emotion in enumerate(unique_emotions)}\n",
    "EMOTIONS = {v: k for k, v in EMOTIONS.items()}\n",
    "EMOTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"emotion\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['emotion'] = data['emotion'].str.strip().str.lower()\n",
    "data['emotion'] = data[\"emotion\"].map(EMOTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T09:59:21.999820Z",
     "iopub.status.busy": "2024-09-20T09:59:21.999439Z",
     "iopub.status.idle": "2024-09-20T09:59:22.020666Z",
     "shell.execute_reply": "2024-09-20T09:59:22.019820Z",
     "shell.execute_reply.started": "2024-09-20T09:59:21.999781Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"number of data:{len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !uv add memory-profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T09:59:24.720452Z",
     "iopub.status.busy": "2024-09-20T09:59:24.720069Z",
     "iopub.status.idle": "2024-09-20T10:00:16.335733Z",
     "shell.execute_reply": "2024-09-20T10:00:16.334922Z",
     "shell.execute_reply.started": "2024-09-20T09:59:24.720413Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%memit\n",
    "mel_spectrograms = []\n",
    "signals = [] \n",
    "SAMPLE_RATE = 16000\n",
    "\n",
    "for i, file_path in enumerate(data.path):\n",
    "    # Load the audio file with librosa; load 3 seconds of audio starting from 0.5 seconds\n",
    "    audio, sample_rate = librosa.load(file_path, duration=3, offset=0.5, sr=SAMPLE_RATE)\n",
    "    \n",
    "    # Create an empty signal of length 3 seconds (SAMPLE_RATE * 3) filled with zeros\n",
    "    signal = np.zeros(int(SAMPLE_RATE * 3))\n",
    "    \n",
    "    signal[:len(audio)] = audio\n",
    "    \n",
    "    signals.append(signal)\n",
    "    \n",
    "    print(\"\\rProcessed {}/{} files\".format(i + 1, len(data)), end='')\n",
    "signals = np.stack(signals, axis=0)\n",
    "# np.save(\".data/signals.npy\", signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(signals[0])\n",
    "plt.xlabel(\"Sample Number\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(signals[0], rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T10:00:20.048845Z",
     "iopub.status.busy": "2024-09-20T10:00:20.048338Z",
     "iopub.status.idle": "2024-09-20T10:00:21.860703Z",
     "shell.execute_reply": "2024-09-20T10:00:21.859720Z",
     "shell.execute_reply.started": "2024-09-20T10:00:20.048807Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%memit\n",
    "X = signals  # Assign the processed signals to X for simplicity\n",
    "del signals\n",
    "\n",
    "train_ind, test_ind, val_ind = [], [], [] \n",
    "X_train, X_val, X_test = [], [], [] \n",
    "Y_train, Y_val, Y_test = [], [], []  \n",
    "\n",
    "# Loop over each emotion category (based on the EMOTIONS dictionary)\n",
    "for emotion in range(len(EMOTIONS)):\n",
    "    # Get indices of all samples belonging to the current emotion\n",
    "    emotion_ind = list(data.loc[data.emotion == emotion, 'emotion'].index)\n",
    "\n",
    "    # Shuffle the indices randomly\n",
    "    emotion_ind = np.random.permutation(emotion_ind)\n",
    "\n",
    "    m = len(emotion_ind)\n",
    "    ind_train = emotion_ind[:int(0.8 * m)]\n",
    "    ind_val = emotion_ind[int(0.8 * m):int(0.9 * m)]\n",
    "    ind_test = emotion_ind[int(0.9 * m):]\n",
    "\n",
    "    X_train.append(X[ind_train, :])\n",
    "    Y_train.append(np.array([emotion] * len(ind_train), dtype=np.int32)) \n",
    "    \n",
    "    X_val.append(X[ind_val, :])\n",
    "    Y_val.append(np.array([emotion] * len(ind_val), dtype=np.int32))\n",
    "    \n",
    "    X_test.append(X[ind_test, :])\n",
    "    Y_test.append(np.array([emotion] * len(ind_test), dtype=np.int32))\n",
    "    \n",
    "    # Store the indices used for train, validation, and test sets\n",
    "    train_ind.append(ind_train)\n",
    "    test_ind.append(ind_test)\n",
    "    val_ind.append(ind_val)\n",
    "\n",
    "X_train = np.concatenate(X_train, 0)\n",
    "X_val = np.concatenate(X_val, 0)\n",
    "X_test = np.concatenate(X_test, 0)\n",
    "Y_train = np.concatenate(Y_train, 0)\n",
    "Y_val = np.concatenate(Y_val, 0)\n",
    "Y_test = np.concatenate(Y_test, 0)\n",
    "\n",
    "train_ind = np.concatenate(train_ind, 0)\n",
    "val_ind = np.concatenate(val_ind, 0)\n",
    "test_ind = np.concatenate(test_ind, 0)\n",
    "\n",
    "# Print the shapes of the training, validation, and test sets for both data (X) and labels (Y)\n",
    "print(f'X_train: {X_train.shape}, Y_train: {Y_train.shape}')\n",
    "print(f'X_val: {X_val.shape}, Y_val: {Y_val.shape}')\n",
    "print(f'X_test: {X_test.shape}, Y_test: {Y_test.shape}')\n",
    "\n",
    "# Check if all indices are unique (i.e., there are no overlaps between train, validation, and test sets)\n",
    "unique, count = np.unique(np.concatenate([train_ind, test_ind, val_ind], 0), return_counts=True)\n",
    "print(\"Number of unique indexes is {}, out of {}\".format(sum(count == 1), X.shape[0]))\n",
    "\n",
    "# Delete the original signals array to free up memory\n",
    "del X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T10:00:36.383470Z",
     "iopub.status.busy": "2024-09-20T10:00:36.383084Z",
     "iopub.status.idle": "2024-09-20T10:00:36.390955Z",
     "shell.execute_reply": "2024-09-20T10:00:36.389838Z",
     "shell.execute_reply.started": "2024-09-20T10:00:36.383433Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def addAWGN(signal, num_bits=16, augmented_num=2, snr_low=15, snr_high=30): \n",
    "    \n",
    "    signal_len = len(signal)  # Length of the input signal\n",
    "    noise = np.random.normal(size=(augmented_num, signal_len))\n",
    "\n",
    "    norm_constant = 2.0 ** (num_bits - 1)\n",
    "    signal_norm = signal / norm_constant \n",
    "    noise_norm = noise / norm_constant    \n",
    "    \n",
    "    s_power = np.sum(signal_norm ** 2) / signal_len\n",
    "    \n",
    "    n_power = np.sum(noise_norm ** 2, axis=1) / signal_len\n",
    "    \n",
    "    target_snr = np.random.randint(snr_low, snr_high)\n",
    "    \n",
    "    K = np.sqrt((s_power / n_power) * 10 ** (- target_snr / 10))\n",
    "    \n",
    "    K = np.ones((signal_len, augmented_num)) * K\n",
    "    \n",
    "    return signal + K.T * noise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T10:00:41.156107Z",
     "iopub.status.busy": "2024-09-20T10:00:41.155706Z",
     "iopub.status.idle": "2024-09-20T10:01:17.598916Z",
     "shell.execute_reply": "2024-09-20T10:01:17.597829Z",
     "shell.execute_reply.started": "2024-09-20T10:00:41.156070Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%memit\n",
    "aug_signals = []  # List to store the augmented signals\n",
    "aug_labels = []   # List to store the corresponding labels for the augmented signals\n",
    "\n",
    "# Loop through each sample in the training set\n",
    "for i in range(X_train.shape[0]):\n",
    "    signal = X_train[i, :]  # Extract the i-th signal from X_train\n",
    "    \n",
    "    # Generate augmented signals by adding Additive White Gaussian Noise (AWGN) to the original signal\n",
    "    augmented_signals = addAWGN(signal)\n",
    "    \n",
    "    # Loop through each of the generated augmented signals\n",
    "    for j in range(augmented_signals.shape[0]):\n",
    "        # Append the emotion label of the current sample to the augmented labels\n",
    "        aug_labels.append(data.loc[i, \"emotion\"])\n",
    "        \n",
    "        # Append the j-th augmented signal to the list of augmented signals\n",
    "        aug_signals.append(augmented_signals[j, :])\n",
    "        \n",
    "        # Create a temporary DataFrame for the current data row\n",
    "        temp_df = pd.DataFrame(data.iloc[i]).T\n",
    "        \n",
    "        # Concatenate the current row to the original DataFrame using pd.concat\n",
    "        data = pd.concat([data, temp_df], ignore_index=True)\n",
    "    \n",
    "    # Print the progress of the augmentation process\n",
    "    print(\"\\rProcessed {}/{} files\".format(i, X_train.shape[0]), end='')\n",
    "\n",
    "# Convert the list of augmented signals into a NumPy array for easier concatenation\n",
    "aug_signals = np.stack(aug_signals, axis=0)\n",
    "\n",
    "# Concatenate the original training signals with the augmented signals\n",
    "X_train = np.concatenate([X_train, aug_signals], axis=0)\n",
    "\n",
    "# Convert the list of augmented labels into a NumPy array\n",
    "aug_labels = np.stack(aug_labels, axis=0)\n",
    "\n",
    "# Concatenate the original training labels with the augmented labels\n",
    "Y_train = np.concatenate([Y_train, aug_labels])\n",
    "\n",
    "# Print final shapes of the augmented training data and labels\n",
    "print('')\n",
    "print(f'X_train: {X_train.shape}, Y_train: {Y_train.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T10:01:17.601686Z",
     "iopub.status.busy": "2024-09-20T10:01:17.601237Z",
     "iopub.status.idle": "2024-09-20T10:01:19.224287Z",
     "shell.execute_reply": "2024-09-20T10:01:19.223367Z",
     "shell.execute_reply.started": "2024-09-20T10:01:17.601631Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%memit\n",
    "def getMELspectrogram(audio, sample_rate):\n",
    "    mel_spec=librosa.feature.melspectrogram(y=audio,sr=sample_rate,n_fft=1024,win_length=512,window='hamming',hop_length=256,n_mels=128,fmax=sample_rate/2)\n",
    "    # Convert power spectrogram to decibel scale\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    return mel_spec_db\n",
    "\n",
    "audio, sample_rate = librosa.load(data.loc[0,'path'], duration=3, offset=0.5, sr=SAMPLE_RATE)\n",
    "# Create an empty signal array of length equal to 3 seconds\n",
    "signal = np.zeros((int(SAMPLE_RATE*3,)))\n",
    "\n",
    "# Fill the signal array with the audio data\n",
    "signal[:len(audio)] = audio\n",
    "\n",
    "mel_spectrogram = getMELspectrogram(signal, SAMPLE_RATE)\n",
    "\n",
    "librosa.display.specshow(mel_spectrogram, y_axis='mel', x_axis='time')\n",
    "\n",
    "print('MEL spectrogram shape: ',mel_spectrogram.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T10:01:19.226124Z",
     "iopub.status.busy": "2024-09-20T10:01:19.225574Z",
     "iopub.status.idle": "2024-09-20T10:03:44.395558Z",
     "shell.execute_reply": "2024-09-20T10:03:44.394587Z",
     "shell.execute_reply.started": "2024-09-20T10:01:19.226076Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# List to store the MEL spectrograms for the training set\n",
    "mel_train = []\n",
    "print(\"Calculating MEL spectrograms for train set\")\n",
    "\n",
    "for i in range(X_train.shape[0]):\n",
    "    mel_spectrogram = getMELspectrogram(X_train[i, :], sample_rate=SAMPLE_RATE)\n",
    "    \n",
    "    mel_train.append(mel_spectrogram)\n",
    " \n",
    "    print(\"\\rProcessed {}/{} files\".format(i, X_train.shape[0]), end='')\n",
    "\n",
    "print('') \n",
    "del X_train  \n",
    "\n",
    "mel_val = []\n",
    "print(\"Calculating MEL spectrograms for validation set\")\n",
    "\n",
    "for i in range(X_val.shape[0]):\n",
    "    mel_spectrogram = getMELspectrogram(X_val[i, :], sample_rate=SAMPLE_RATE)\n",
    "\n",
    "    mel_val.append(mel_spectrogram)\n",
    "\n",
    "    print(\"\\rProcessed {}/{} files\".format(i, X_val.shape[0]), end='')\n",
    "\n",
    "print('') \n",
    "del X_val \n",
    "\n",
    "mel_test = []\n",
    "print(\"Calculating MEL spectrograms for test set\")\n",
    "\n",
    "for i in range(X_test.shape[0]):\n",
    "    mel_spectrogram = getMELspectrogram(X_test[i, :], sample_rate=SAMPLE_RATE)\n",
    "    \n",
    "    mel_test.append(mel_spectrogram)\n",
    "\n",
    "    print(\"\\rProcessed {}/{} files\".format(i, X_test.shape[0]), end='')\n",
    "\n",
    "print('') \n",
    "del X_test \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T10:03:44.399169Z",
     "iopub.status.busy": "2024-09-20T10:03:44.398436Z",
     "iopub.status.idle": "2024-09-20T10:03:44.407373Z",
     "shell.execute_reply": "2024-09-20T10:03:44.406014Z",
     "shell.execute_reply.started": "2024-09-20T10:03:44.399123Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def splitIntoChunks(mel_spec, win_size, stride):\n",
    "    t = mel_spec.shape[1]\n",
    "    \n",
    "    num_of_chunks = int(t / stride)\n",
    "\n",
    "    chunks = []\n",
    "\n",
    "    for i in range(num_of_chunks):\n",
    "        chunk = mel_spec[:, i * stride:i * stride + win_size]\n",
    "        if chunk.shape[1] == win_size:\n",
    "            chunks.append(chunk)\n",
    "\n",
    "    return np.stack(chunks, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T10:03:44.410506Z",
     "iopub.status.busy": "2024-09-20T10:03:44.409549Z",
     "iopub.status.idle": "2024-09-20T10:03:49.028906Z",
     "shell.execute_reply": "2024-09-20T10:03:49.027963Z",
     "shell.execute_reply.started": "2024-09-20T10:03:44.410463Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "mel_train_chunked = []\n",
    "\n",
    "for mel_spec in mel_train:\n",
    "    chunks = splitIntoChunks(mel_spec, win_size=128, stride=64)\n",
    "    mel_train_chunked.append(chunks)\n",
    "print(\"Number of chunks is {}\".format(chunks.shape[0]))\n",
    "mel_val_chunked = []\n",
    "\n",
    "\n",
    "for mel_spec in mel_val:\n",
    "    chunks = splitIntoChunks(mel_spec, win_size=128, stride=64)\n",
    "    mel_val_chunked.append(chunks)\n",
    "\n",
    "print(\"Number of chunks is {}\".format(chunks.shape[0]))\n",
    "\n",
    "mel_test_chunked = []\n",
    "\n",
    "\n",
    "for mel_spec in mel_test:\n",
    "    chunks = splitIntoChunks(mel_spec, win_size=128, stride=64)\n",
    "    mel_test_chunked.append(chunks)\n",
    "print(\"Number of chunks is {}\".format(chunks.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T10:03:49.030628Z",
     "iopub.status.busy": "2024-09-20T10:03:49.030246Z",
     "iopub.status.idle": "2024-09-20T10:03:51.668337Z",
     "shell.execute_reply": "2024-09-20T10:03:51.667395Z",
     "shell.execute_reply.started": "2024-09-20T10:03:49.030585Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#creating a model\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# TimeDistributed layer for applying a module to each time step in a sequence\n",
    "class TimeDistributed(nn.Module):\n",
    "    def __init__(self, module):\n",
    "        super(TimeDistributed, self).__init__()\n",
    "        self.module = module\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.size()) <= 2:\n",
    "            return self.module(x)\n",
    "\n",
    "        if len(x.size()) == 3:\n",
    "            x_reshape = x.contiguous().view(-1, x.size(2)) \n",
    "        elif len(x.size()) == 4: \n",
    "            x_reshape = x.contiguous().view(-1, x.size(2), x.size(3))\n",
    "        else: \n",
    "            x_reshape = x.contiguous().view(-1, x.size(2), x.size(3), x.size(4))\n",
    "        \n",
    "        # Apply the module to the reshaped tensor\n",
    "        y = self.module(x_reshape)\n",
    "        \n",
    "        \n",
    "        if len(x.size()) == 3:\n",
    "            y = y.contiguous().view(x.size(0), -1, y.size(1)) \n",
    "        elif len(x.size()) == 4:\n",
    "            y = y.contiguous().view(x.size(0), -1, y.size(1), y.size(2))  \n",
    "        else:\n",
    "            y = y.contiguous().view(x.size(0), -1, y.size(1), y.size(2), y.size(3))  \n",
    "        return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T10:03:51.670037Z",
     "iopub.status.busy": "2024-09-20T10:03:51.669571Z",
     "iopub.status.idle": "2024-09-20T10:03:51.686236Z",
     "shell.execute_reply": "2024-09-20T10:03:51.685328Z",
     "shell.execute_reply.started": "2024-09-20T10:03:51.670001Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, num_emotions):\n",
    "        \"\"\"\n",
    "        Initialize the HybridModel with convolutional, LSTM, and attention layers.\n",
    "\n",
    "        Parameters:\n",
    "        - num_emotions: Number of emotion classes for classification.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Convolutional Block\n",
    "        self.conv2Dblock = nn.Sequential(\n",
    "            # 1. Convolutional Block\n",
    "            TimeDistributed(nn.Conv2d(in_channels=1,\n",
    "                                   out_channels=16,\n",
    "                                   kernel_size=3,\n",
    "                                   stride=1,\n",
    "                                   padding=1)),\n",
    "            TimeDistributed(nn.BatchNorm2d(16)),\n",
    "            TimeDistributed(nn.ReLU()),\n",
    "            TimeDistributed(nn.MaxPool2d(kernel_size=2, stride=2)),\n",
    "            TimeDistributed(nn.Dropout(p=0.3)),\n",
    "            # 2. Convolutional Block\n",
    "            TimeDistributed(nn.Conv2d(in_channels=16,\n",
    "                                   out_channels=32,\n",
    "                                   kernel_size=3,\n",
    "                                   stride=1,\n",
    "                                   padding=1)),\n",
    "            TimeDistributed(nn.BatchNorm2d(32)),\n",
    "            TimeDistributed(nn.ReLU()),\n",
    "            TimeDistributed(nn.MaxPool2d(kernel_size=4, stride=4)),\n",
    "            TimeDistributed(nn.Dropout(p=0.3)),\n",
    "            # 3. Convolutional Block\n",
    "            TimeDistributed(nn.Conv2d(in_channels=32,\n",
    "                                   out_channels=64,\n",
    "                                   kernel_size=3,\n",
    "                                   stride=1,\n",
    "                                   padding=1)),\n",
    "            TimeDistributed(nn.BatchNorm2d(64)),\n",
    "            TimeDistributed(nn.ReLU()),\n",
    "            TimeDistributed(nn.MaxPool2d(kernel_size=4, stride=4)),\n",
    "            TimeDistributed(nn.Dropout(p=0.3))\n",
    "        )\n",
    "        \n",
    "        # LSTM Block\n",
    "        hidden_size = 64\n",
    "        self.lstm = nn.LSTM(input_size=1024, hidden_size=hidden_size, bidirectional=True, batch_first=True)\n",
    "        self.dropout_lstm = nn.Dropout(p=0.4)\n",
    "        self.attention_linear = nn.Linear(2 * hidden_size, 1)  # 2 * hidden_size for bidirectional LSTM\n",
    "        \n",
    "        # Linear layer for output classification\n",
    "        self.out_linear = nn.Linear(2 * hidden_size, num_emotions)\n",
    "    \n",
    "    def forward(self, x):  \n",
    "        conv_embedding = self.conv2Dblock(x)\n",
    "        \n",
    "        conv_embedding = torch.flatten(conv_embedding, start_dim=2)\n",
    "        \n",
    "        # Apply LSTM layers\n",
    "        lstm_embedding, (h, c) = self.lstm(conv_embedding)\n",
    "        lstm_embedding = self.dropout_lstm(lstm_embedding)\n",
    "        \n",
    "        # Compute attention weights\n",
    "        batch_size, T, _ = lstm_embedding.shape\n",
    "        attention_weights = [None] * T\n",
    "        for t in range(T):\n",
    "            embedding = lstm_embedding[:, t, :]\n",
    "            attention_weights[t] = self.attention_linear(embedding)\n",
    "        \n",
    "        # Normalize attention weights\n",
    "        attention_weights_norm = nn.functional.softmax(torch.stack(attention_weights, -1), dim=-1)\n",
    "        \n",
    "        # Apply attention to LSTM outputs\n",
    "        attention = torch.bmm(attention_weights_norm, lstm_embedding)  # (Bx1xT)*(B,T,hidden_size*2) = (B,1,2*hidden_size)\n",
    "        attention = torch.squeeze(attention, 1)\n",
    "        \n",
    "        # Compute output logits and softmax probabilities\n",
    "        output_logits = self.out_linear(attention)\n",
    "        output_softmax = nn.functional.softmax(output_logits, dim=1)\n",
    "        \n",
    "        return output_logits, output_softmax, attention_weights_norm\n",
    "    \n",
    "    \n",
    "def loss_fnc(predictions, targets):\n",
    "\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "    return loss_function(input=predictions, target=targets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "comet_api_key = os.getenv('API_KEY')\n",
    "project_name = os.getenv('PROJECT_NAME')\n",
    "\n",
    "experiment = comet_ml.Experiment(api_key=comet_api_key, project_name=project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True labels for confusion matrix logging\n",
    "emotion_labels = {0: 'surprise', 1: 'fear', 2: 'angry', 3: 'neutral', 4: 'sad', 5: 'disgust', 6: 'happy'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T10:03:51.688346Z",
     "iopub.status.busy": "2024-09-20T10:03:51.687900Z",
     "iopub.status.idle": "2024-09-20T10:03:51.697336Z",
     "shell.execute_reply": "2024-09-20T10:03:51.696586Z",
     "shell.execute_reply.started": "2024-09-20T10:03:51.688301Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#training process\n",
    "def make_train_step(model, loss_fnc, optimizer):\n",
    "    def train_step(X,Y):\n",
    "        model.train()\n",
    "        output_logits, output_softmax, attention_weights_norm = model(X)\n",
    "        predictions = torch.argmax(output_softmax, dim=1)\n",
    "        accuracy = torch.sum(Y == predictions) / float(len(Y))\n",
    "        loss = loss_fnc(output_logits, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        return loss.item(), accuracy * 100\n",
    "    return train_step  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T10:03:51.698696Z",
     "iopub.status.busy": "2024-09-20T10:03:51.698376Z",
     "iopub.status.idle": "2024-09-20T10:03:51.707036Z",
     "shell.execute_reply": "2024-09-20T10:03:51.706187Z",
     "shell.execute_reply.started": "2024-09-20T10:03:51.698662Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def make_validate_fnc(model, loss_fnc):\n",
    "    def validate(X, Y):\n",
    "        # Disable gradient calculations for validation to save memory and computation\n",
    "        with torch.inference_mode():\n",
    "            model.eval()\n",
    "            output_logits, output_softmax, attention_weights_norm = model(X)\n",
    "            predictions = torch.argmax(output_softmax, dim=1)\n",
    "            accuracy = torch.sum(Y == predictions) / float(len(Y))\n",
    "\n",
    "            # Log the confusion matrix to Comet\n",
    "            experiment.log_confusion_matrix(\n",
    "                y_true=Y,\n",
    "                y_predicted=predictions,\n",
    "                labels=list(emotion_labels.values())\n",
    "            )\n",
    "\n",
    "            loss = loss_fnc(output_logits, Y)\n",
    "            \n",
    "        return loss.item(), accuracy * 100, predictions\n",
    "    \n",
    "    return validate  # Return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T10:03:51.710018Z",
     "iopub.status.busy": "2024-09-20T10:03:51.709679Z",
     "iopub.status.idle": "2024-09-20T10:03:56.012804Z",
     "shell.execute_reply": "2024-09-20T10:03:56.011932Z",
     "shell.execute_reply.started": "2024-09-20T10:03:51.709985Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert the list of chunked mel spectrograms for training, validation, and test sets into numpy arrays\n",
    "X_train = np.stack(mel_train_chunked, axis=0)  \n",
    "X_train = np.expand_dims(X_train, 2) \n",
    "print('Shape of X_train: ', X_train.shape)\n",
    "\n",
    "X_val = np.stack(mel_val_chunked, axis=0) \n",
    "X_val = np.expand_dims(X_val, 2) \n",
    "print('Shape of X_val: ', X_val.shape)\n",
    "\n",
    "X_test = np.stack(mel_test_chunked, axis=0)\n",
    "X_test = np.expand_dims(X_test, 2)  \n",
    "print('Shape of X_test: ', X_test.shape)\n",
    "\n",
    "\n",
    "del mel_train_chunked\n",
    "del mel_train\n",
    "del mel_val_chunked\n",
    "del mel_val\n",
    "del mel_test_chunked\n",
    "del mel_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T10:03:56.014141Z",
     "iopub.status.busy": "2024-09-20T10:03:56.013844Z",
     "iopub.status.idle": "2024-09-20T10:04:05.927767Z",
     "shell.execute_reply": "2024-09-20T10:04:05.926748Z",
     "shell.execute_reply.started": "2024-09-20T10:03:56.014108Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Reshape X_train, scale it, and reshape back\n",
    "b, t, c, h, w = X_train.shape\n",
    "X_train = np.reshape(X_train, newshape=(b, -1))  # Flatten each sample\n",
    "X_train = scaler.fit_transform(X_train)  # Fit and transform training data\n",
    "X_train = np.reshape(X_train, newshape=(b, t, c, h, w))  # Reshape back to original form\n",
    "\n",
    "# Save the scaler to a file\n",
    "scaler_path = get_models_dir(\"speech_sentiment/cnn_bilstm\") / \"scaler.pkl\"\n",
    "joblib.dump(scaler, scaler_path)\n",
    "\n",
    "b, t, c, h, w = X_test.shape\n",
    "X_test = np.reshape(X_test, newshape=(b, -1)) \n",
    "X_test = scaler.transform(X_test)  \n",
    "X_test = np.reshape(X_test, newshape=(b, t, c, h, w)) \n",
    "\n",
    "b, t, c, h, w = X_val.shape\n",
    "X_val = np.reshape(X_val, newshape=(b, -1))\n",
    "X_val = scaler.transform(X_val)  \n",
    "X_val = np.reshape(X_val, newshape=(b, t, c, h, w))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T10:04:05.929601Z",
     "iopub.status.busy": "2024-09-20T10:04:05.929258Z",
     "iopub.status.idle": "2024-09-20T10:55:19.366426Z",
     "shell.execute_reply": "2024-09-20T10:55:19.365432Z",
     "shell.execute_reply.started": "2024-09-20T10:04:05.929563Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "EPOCHS=300\n",
    "DATASET_SIZE = X_train.shape[0]\n",
    "BATCH_SIZE = 32\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "print('Selected device is {}'.format(device))\n",
    "model = HybridModel(num_emotions=len(EMOTIONS)).to(device) \n",
    "print('Number of trainable params: ',sum(p.numel() for p in model.parameters()))  \n",
    "OPTIMIZER = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-3, momentum=0.8)  # Define the optimizer\n",
    "\n",
    "train_step = make_train_step(model, loss_fnc, optimizer=OPTIMIZER) \n",
    "validate = make_validate_fnc(model, loss_fnc) \n",
    "losses = []  \n",
    "val_losses = [] \n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Shuffle data at the start of each epoch\n",
    "    ind = np.random.permutation(DATASET_SIZE)\n",
    "    X_train = X_train[ind, :, :, :, :]\n",
    "    Y_train = Y_train[ind]\n",
    "\n",
    "    epoch_acc = 0  \n",
    "    epoch_loss = 0  \n",
    "    iters = int(DATASET_SIZE / BATCH_SIZE)  # Number of iterations per epoch\n",
    "\n",
    "    # Iterate over batches\n",
    "    for i in range(iters):\n",
    "        batch_start = i * BATCH_SIZE\n",
    "        batch_end = min(batch_start + BATCH_SIZE, DATASET_SIZE)\n",
    "        actual_batch_size = batch_end - batch_start\n",
    "\n",
    "        X = X_train[batch_start:batch_end, :, :, :, :]\n",
    "        Y = Y_train[batch_start:batch_end]\n",
    "\n",
    "        # Move data to the appropriate device\n",
    "        X_tensor = torch.tensor(X, device=device).float()\n",
    "        Y_tensor = torch.tensor(Y, dtype=torch.long, device=device)\n",
    "\n",
    "        #training step\n",
    "        loss, acc = train_step(X_tensor, Y_tensor)\n",
    "        epoch_acc += acc * actual_batch_size / DATASET_SIZE\n",
    "        epoch_loss += loss * actual_batch_size / DATASET_SIZE \n",
    "\n",
    "        # Log metrics for this step\n",
    "        experiment.log_metric(\"train_loss\", epoch_loss, step=epoch)\n",
    "        experiment.log_metric(\"train_accuracy\", epoch_acc, step=epoch)\n",
    "\n",
    "        print(f\"\\r Epoch {epoch}: iteration {i}/{iters}\", end='')  # Display training progress\n",
    "\n",
    "    # Validation after each epoch\n",
    "    X_val_tensor = torch.tensor(X_val, device=device).float()\n",
    "    Y_val_tensor = torch.tensor(Y_val, dtype=torch.long, device=device)\n",
    "    val_loss, val_acc, _ = validate(X_val_tensor, Y_val_tensor)\n",
    "\n",
    "    # Log metrics for this step\n",
    "    experiment.log_metric(\"val_loss\", val_loss, step=epoch)\n",
    "    experiment.log_metric(\"val_accuracy\", val_acc, step=epoch)\n",
    "\n",
    "    losses.append(epoch_loss) \n",
    "    val_losses.append(val_loss)  \n",
    "\n",
    "    # Print summary of the epoch\n",
    "    print('')\n",
    "    print(f\"Epoch {epoch} --> loss:{epoch_loss:.4f}, acc:{epoch_acc:.2f}%, val_loss:{val_loss:.4f}, val_acc:{val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T10:55:54.247530Z",
     "iopub.status.busy": "2024-09-20T10:55:54.246925Z",
     "iopub.status.idle": "2024-09-20T10:55:54.505194Z",
     "shell.execute_reply": "2024-09-20T10:55:54.504034Z",
     "shell.execute_reply.started": "2024-09-20T10:55:54.247487Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.plot(losses,'b')\n",
    "plt.plot(val_losses,'r')\n",
    "plt.legend(['train loss','val loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T10:57:55.316927Z",
     "iopub.status.busy": "2024-09-20T10:57:55.316495Z",
     "iopub.status.idle": "2024-09-20T10:57:55.333279Z",
     "shell.execute_reply": "2024-09-20T10:57:55.332469Z",
     "shell.execute_reply.started": "2024-09-20T10:57:55.316886Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_path = get_models_dir(\"speech_sentiment/cnn_bilstm\") / 'speech_sentiment_asr.pt'\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f'Model is saved to {model_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T10:59:58.397916Z",
     "iopub.status.busy": "2024-09-20T10:59:58.397516Z",
     "iopub.status.idle": "2024-09-20T10:59:58.422573Z",
     "shell.execute_reply": "2024-09-20T10:59:58.421602Z",
     "shell.execute_reply.started": "2024-09-20T10:59:58.397876Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_path = get_models_dir(\"speech_sentiment/cnn_bilstm\") / 'speech_sentiment_asr.pt'\n",
    "model = HybridModel(len(EMOTIONS))\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T11:06:28.448812Z",
     "iopub.status.busy": "2024-09-20T11:06:28.448175Z",
     "iopub.status.idle": "2024-09-20T11:06:28.685738Z",
     "shell.execute_reply": "2024-09-20T11:06:28.684758Z",
     "shell.execute_reply.started": "2024-09-20T11:06:28.448759Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_test_tensor = torch.tensor(X_test,device=device).float()\n",
    "Y_test_tensor = torch.tensor(Y_test,dtype=torch.long,device=device)\n",
    "test_loss, test_acc, predictions = validate(X_test_tensor,Y_test_tensor)\n",
    "print(f'Test loss is {test_loss:.3f}')\n",
    "print(f'Test accuracy is {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T11:06:30.177183Z",
     "iopub.status.busy": "2024-09-20T11:06:30.176333Z",
     "iopub.status.idle": "2024-09-20T11:06:30.837094Z",
     "shell.execute_reply": "2024-09-20T11:06:30.836136Z",
     "shell.execute_reply.started": "2024-09-20T11:06:30.177139Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "\n",
    "predictions = predictions.cpu().numpy()\n",
    "cm = confusion_matrix(Y_test, predictions)\n",
    "# names = [EMOTIONS[ind] for ind in range(len(EMOTIONS))]\n",
    "names = [k for k, v in EMOTIONS.items()]\n",
    "df_cm = pd.DataFrame(cm, index=names, columns=names)\n",
    "# plt.figure(figsize=(10,7))\n",
    "sn.set(font_scale=1.4) # for label size\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T11:06:58.394646Z",
     "iopub.status.busy": "2024-09-20T11:06:58.393890Z",
     "iopub.status.idle": "2024-09-20T11:06:58.696623Z",
     "shell.execute_reply": "2024-09-20T11:06:58.695743Z",
     "shell.execute_reply.started": "2024-09-20T11:06:58.394603Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Correlation between emotion intensity and correct prediction\n",
    "correct_strong = 0\n",
    "correct_normal = 0\n",
    "wrong_strong = 0\n",
    "wrong_normal = 0\n",
    "for i in range(len(X_test)):\n",
    "    intensity = data.loc[test_ind[i],'Emotion intensity']\n",
    "    if Y_test[i] == predictions[i]: # correct prediction\n",
    "        if  intensity == 'normal':\n",
    "            correct_normal += 1\n",
    "        else:\n",
    "            correct_strong += 1\n",
    "    else: # wrong prediction\n",
    "        if intensity == 'normal':\n",
    "            wrong_normal += 1\n",
    "        else:\n",
    "            wrong_strong += 1\n",
    "array = np.array([[wrong_normal,wrong_strong],[correct_normal,correct_strong]])\n",
    "df = pd.DataFrame(array,['wrong','correct'],['normal','strong'])\n",
    "sn.set_theme(font_scale=1.4) # for label size\n",
    "sn.heatmap(df, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T11:07:37.511793Z",
     "iopub.status.busy": "2024-09-20T11:07:37.510717Z",
     "iopub.status.idle": "2024-09-20T11:07:37.842225Z",
     "shell.execute_reply": "2024-09-20T11:07:37.841141Z",
     "shell.execute_reply.started": "2024-09-20T11:07:37.511717Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#correlation between gender and corectness\n",
    "correct_male = 0\n",
    "correct_female = 0\n",
    "wrong_male = 0\n",
    "wrong_female = 0\n",
    "for i in range(len(X_test)):\n",
    "    gender = data.loc[test_ind[i],'Gender']\n",
    "    if Y_test[i] == predictions[i]: # correct prediction\n",
    "        if  gender == 'male':\n",
    "            correct_male += 1\n",
    "        else:\n",
    "            correct_female += 1\n",
    "    else: # wrong prediction\n",
    "        if gender == 'male':\n",
    "            wrong_male += 1\n",
    "        else:\n",
    "            wrong_female += 1\n",
    "array = np.array([[wrong_male,wrong_female],[correct_male,correct_female]])\n",
    "df = pd.DataFrame(array,['wrong','correct'],['male','female'])\n",
    "sn.set_theme(font_scale=1.4) # for label size\n",
    "sn.heatmap(df, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 107620,
     "sourceId": 256618,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
