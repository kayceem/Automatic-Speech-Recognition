{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9IXTuBQnBhWj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Configuring Pandas to exhibit larger columns\n",
        "'''\n",
        "This is going to allow us to fully read the dialogues and their summary\n",
        "'''\n",
        "pd.set_option('display.max_colwidth', 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6TD-iPMaBnZz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import gaussian_kde\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.figure_factory as ff\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "T-dCdc9FBq9b"
      },
      "outputs": [],
      "source": [
        "# Configuring notebook\n",
        "colormap = 'cividis'\n",
        "template = 'plotly_dark'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SxZk4AJmB2Wi"
      },
      "outputs": [],
      "source": [
        "def display_feature_list(features, feature_type):\n",
        "\n",
        "    '''\n",
        "    This function displays the features within each list for each type of data\n",
        "    '''\n",
        "    print(f\"\\n{feature_type} Features: \")\n",
        "    print(', '.join(features) if features else 'None')\n",
        "\n",
        "def describe_df(df):\n",
        "    \"\"\"\n",
        "    This function prints some basic info on the dataset and\n",
        "    sets global variables for feature lists.\n",
        "    \"\"\"\n",
        "\n",
        "    global categorical_features, continuous_features, binary_features\n",
        "    categorical_features = [col for col in df.columns if df[col].dtype == 'object']\n",
        "    binary_features = [col for col in df.columns if df[col].nunique() <= 2 and df[col].dtype != 'object']\n",
        "    continuous_features = [col for col in df.columns if df[col].dtype != 'object' and col not in binary_features]\n",
        "\n",
        "    print(f\"\\n{type(df).__name__} shape: {df.shape}\")\n",
        "    print(f\"\\n{df.shape[0]:,.0f} samples\")\n",
        "    print(f\"\\n{df.shape[1]:,.0f} attributes\")\n",
        "    print(f'\\nMissing Data: \\n{df.isnull().sum()}')\n",
        "    print(f'\\nDuplicates: {df.duplicated().sum()}')\n",
        "    print(f'\\nData Types: \\n{df.dtypes}')\n",
        "\n",
        "    #negative_valued_features = [col for col in df.columns if (df[col] < 0).any()]\n",
        "    #print(f'\\nFeatures with Negative Values: {\", \".join(negative_valued_features) if negative_valued_features else \"None\"}')\n",
        "\n",
        "    display_feature_list(categorical_features, 'Categorical')\n",
        "    display_feature_list(continuous_features, 'Continuous')\n",
        "    display_feature_list(binary_features, 'Binary')\n",
        "\n",
        "    print(f'\\n{type(df).__name__} Head: \\n')\n",
        "    display(df.head(5))\n",
        "    print(f'\\n{type(df).__name__} Tail: \\n')\n",
        "    display(df.tail(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6CFPrGqGB8cB"
      },
      "outputs": [],
      "source": [
        "def histogram_boxplot(df,hist_color, box_color, height, width, legend, name):\n",
        "    '''\n",
        "    This function plots a Histogram and a Box Plot side by side\n",
        "\n",
        "    Parameters:\n",
        "    hist_color = The color of the histogram\n",
        "    box_color = The color of the boxplots\n",
        "    heigh and width = Image size\n",
        "    legend = Either to display legend or not\n",
        "    '''\n",
        "\n",
        "    features = df.select_dtypes(include = [np.number]).columns.tolist()\n",
        "\n",
        "    for feat in features:\n",
        "        try:\n",
        "            fig = make_subplots(\n",
        "                rows=1,\n",
        "                cols=2,\n",
        "                subplot_titles=[\"Box Plot\", \"Histogram\"],\n",
        "                horizontal_spacing=0.2\n",
        "            )\n",
        "\n",
        "            density = gaussian_kde(df[feat])\n",
        "            x_vals = np.linspace(min(df[feat]), max(df[feat]), 200)\n",
        "            density_vals = density(x_vals)\n",
        "\n",
        "            fig.add_trace(go.Scatter(x=x_vals, y = density_vals, mode = 'lines',\n",
        "                                     fill = 'tozeroy', name=\"Density\", line_color=hist_color), row=1, col=2)\n",
        "            fig.add_trace(go.Box(y=df[feat], name=\"Box Plot\", boxmean=True, line_color=box_color), row=1, col=1)\n",
        "\n",
        "            fig.update_layout(title={'text': f'<b>{name} Word Count<br><sup><i>&nbsp;&nbsp;&nbsp;&nbsp;{feat}</i></sup></b>',\n",
        "                                     'x': .025, 'xanchor': 'left'},\n",
        "                             margin=dict(t=100),\n",
        "                             showlegend=legend,\n",
        "                             template = template,\n",
        "                             #plot_bgcolor=bg_color,paper_bgcolor=paper_color,\n",
        "                             height=height, width=width\n",
        "                            )\n",
        "\n",
        "            fig.update_yaxes(title_text=f\"<b>Words</b>\", row=1, col=1, showgrid=False)\n",
        "            fig.update_xaxes(title_text=\"\", row=1, col=1, showgrid=False)\n",
        "\n",
        "            fig.update_yaxes(title_text=\"<b>Frequency</b>\", row=1, col=2,showgrid=False)\n",
        "            fig.update_xaxes(title_text=f\"<b>Words</b>\", row=1, col=2, showgrid=False)\n",
        "\n",
        "            fig.show()\n",
        "            print('\\n')\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2RosrXmfB_bb"
      },
      "outputs": [],
      "source": [
        "def plot_correlation(df, title, subtitle, height, width, font_size):\n",
        "    '''\n",
        "    This function is resposible to plot a correlation map among features in the dataset.\n",
        "\n",
        "    Parameters:\n",
        "    height = Define height\n",
        "    width = Define width\n",
        "    font_size = Define the font size for the annotations\n",
        "    '''\n",
        "    corr = np.round(df.corr(numeric_only = True), 2)\n",
        "    mask = np.triu(np.ones_like(corr, dtype = bool))\n",
        "    c_mask = np.where(~mask, corr, 100)\n",
        "\n",
        "    c = []\n",
        "    for i in c_mask.tolist()[1:]:\n",
        "        c.append([x for x in i if x != 100])\n",
        "\n",
        "\n",
        "\n",
        "    fig = ff.create_annotated_heatmap(z=c[::-1],\n",
        "                                      x=corr.index.tolist()[:-1],\n",
        "                                      y=corr.columns.tolist()[1:][::-1],\n",
        "                                      colorscale = colormap)\n",
        "\n",
        "    fig.update_layout(title = {'text': f\"<b>{title} Heatmap<br><sup>&nbsp;&nbsp;&nbsp;&nbsp;<i>{subtitle}</i></sup></b>\",\n",
        "                                'x': .025, 'xanchor': 'left', 'y': .95},\n",
        "                    margin = dict(t=210, l = 110),\n",
        "                    yaxis = dict(autorange = 'reversed', showgrid = False),\n",
        "                    xaxis = dict(showgrid = False),\n",
        "                    template = template,\n",
        "                    #plot_bgcolor=bg_color,paper_bgcolor=paper_color,\n",
        "                    height = height, width = width)\n",
        "\n",
        "\n",
        "    fig.add_trace(go.Heatmap(z = c[::-1],\n",
        "                             colorscale = colormap,\n",
        "                             showscale = True,\n",
        "                             visible = False))\n",
        "    fig.data[1].visible = True\n",
        "\n",
        "    for i in range(len(fig.layout.annotations)):\n",
        "        fig.layout.annotations[i].font.size = font_size\n",
        "\n",
        "    fig.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "E_uD4FCLCBYv"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "def compute_tfidf(df_column, ngram_range=(1,1), max_features=15):\n",
        "    vectorizer = TfidfVectorizer(max_features=max_features, stop_words='english', ngram_range=ngram_range)\n",
        "    x = vectorizer.fit_transform(df_column.fillna(''))\n",
        "    df_tfidfvect = pd.DataFrame(x.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "    return df_tfidfvect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IK_T91xGCDep"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/samsum-train.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Loading data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/content/samsum-train.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/samsum-test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m val \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/samsum-validation.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[0;32m~/Code/Fuse/ASR-with-Speech-Sentiment-and-Text-Summarizer/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Code/Fuse/ASR-with-Speech-Sentiment-and-Text-Summarizer/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[0;32m~/Code/Fuse/ASR-with-Speech-Sentiment-and-Text-Summarizer/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Code/Fuse/ASR-with-Speech-Sentiment-and-Text-Summarizer/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
            "File \u001b[0;32m~/Code/Fuse/ASR-with-Speech-Sentiment-and-Text-Summarizer/.venv/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/samsum-train.csv'"
          ]
        }
      ],
      "source": [
        "# Loading data\n",
        "train = pd.read_csv('/content/samsum-train.csv')\n",
        "test = pd.read_csv('/content/samsum-test.csv')\n",
        "val = pd.read_csv('/content/samsum-validation.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EABz5A6ICE99",
        "outputId": "a7278040-42e5-4fb6-905e-511d33fb7f7e"
      },
      "outputs": [],
      "source": [
        "# Extracting info on the training Dataframe\n",
        "describe_df(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EL0ZqYs6C4wB"
      },
      "outputs": [],
      "source": [
        "train = train.dropna() # removing null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6RGNSy4DorD"
      },
      "outputs": [],
      "source": [
        "# Removing 'Id' from categorical features list\n",
        "categorical_features.remove('id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "szyCSF-yDqlU",
        "outputId": "e0f43ba8-f266-4249-8df3-11da031bb1fd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "df_text_lenght = pd.DataFrame() # Creating an empty dataframe\n",
        "for feat in categorical_features: # Iterating through features --> Dialogue & Summary\n",
        "    df_text_lenght[feat] = train[feat].apply(lambda x: len(str(x).split())) #  Counting words for each feature\n",
        "\n",
        "# Plotting histogram-boxplot\n",
        "histogram_boxplot(df_text_lenght,'#89c2e0', '#d500ff', 600, 1000, True, 'Train Dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "rdUFfiOGDsbY",
        "outputId": "44758cac-b73a-483a-f2be-f92131728372"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(max_features = 15,stop_words = 'english') # Top 15 terms\n",
        "x = vectorizer.fit_transform(train['dialogue'])\n",
        "df_tfidfvect = pd.DataFrame(x.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "plot_correlation(df_tfidfvect, 'Unigrams', 'Train - Dialogue', 800, 800, 12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "l3w5KdV5DvGU",
        "outputId": "304bcfe4-f843-404b-be8b-3bdc436fb00a"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(max_features = 15,stop_words = 'english',ngram_range = (2,2)) # Top 15 terms\n",
        "x = vectorizer.fit_transform(train['dialogue'].fillna(''))\n",
        "df_tfidfvect = pd.DataFrame(x.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "plot_correlation(df_tfidfvect, 'Bigrams', 'Train - Dialogue', 800, 800, 12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "6W77FxfWDx6z",
        "outputId": "8d88c597-00aa-4f40-caac-573aea96cae1"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(max_features = 15,stop_words = 'english',ngram_range = (2,2)) # Top 15 terms\n",
        "x = vectorizer.fit_transform(train['summary'].fillna(''))\n",
        "df_tfidfvect = pd.DataFrame(x.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "plot_correlation(df_tfidfvect, 'Bigrams', 'Train - Summary', 800, 800, 12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "id": "McudOlucDz5l",
        "outputId": "bc439f06-18dc-4350-9c40-f102ead75ea0"
      },
      "outputs": [],
      "source": [
        "# Filtering dataset to see those containing the term '15 minutes' in the summary\n",
        "filtered_train = train[train['summary'].str.contains('15 minutes', case=False, na=False)]\n",
        "filtered_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "DRnqrsM0D2-3",
        "outputId": "07d24ce6-fe80-4b8b-feba-399db9fa01db"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(max_features = 15,stop_words = 'english',ngram_range = (3,3)) # Top 15 terms\n",
        "x = vectorizer.fit_transform(train['dialogue'].fillna(''))\n",
        "df_tfidfvect = pd.DataFrame(x.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "plot_correlation(df_tfidfvect, 'Trigrams', 'Train - Dialogue', 800, 800, 12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "niuWyltuD7lW",
        "outputId": "48aee36e-4a3c-4298-9e0b-232584d5908b"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(max_features = 15,stop_words = 'english',ngram_range = (3,3)) # Top 15 terms\n",
        "x = vectorizer.fit_transform(train['summary'].fillna(''))\n",
        "df_tfidfvect = pd.DataFrame(x.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "plot_correlation(df_tfidfvect, 'Trigrams', 'Train - Summary', 800, 800, 12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ebrB5iNfD-P9",
        "outputId": "7390353c-4299-4091-ddd9-712af8321f57"
      },
      "outputs": [],
      "source": [
        "# Extracting info on the test dataset\n",
        "describe_df(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPMpkydrHC7k"
      },
      "outputs": [],
      "source": [
        "categorical_features.remove('id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UAE7Szr5HFVw",
        "outputId": "41e9f945-601a-4916-987d-cd23181a7631"
      },
      "outputs": [],
      "source": [
        "df_text_lenght = pd.DataFrame()\n",
        "for feat in categorical_features:\n",
        "    df_text_lenght[feat] = test[feat].apply(lambda x: len(str(x).split()))\n",
        "\n",
        "histogram_boxplot(df_text_lenght,'#89c2e0', '#d500ff', 600, 1000, True, 'Test Dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "0vKhogzwHHFx",
        "outputId": "6d78fead-093e-4e5a-c9bb-e082a436af77"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(max_features = 15,stop_words = 'english') # Top 15 terms\n",
        "x = vectorizer.fit_transform(test['dialogue'].fillna(''))\n",
        "df_tfidfvect = pd.DataFrame(x.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "plot_correlation(df_tfidfvect, 'Unigrams', 'Test - Dialogue', 800, 800, 12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "-qF0RaGiHJOk",
        "outputId": "6bb005ba-f4e7-4516-ab29-1cf25da668ed"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(max_features = 15,stop_words = 'english') # Top 15 terms\n",
        "x = vectorizer.fit_transform(test['summary'].fillna(''))\n",
        "df_tfidfvect = pd.DataFrame(x.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "plot_correlation(df_tfidfvect, 'Unigrams', 'Test - Summary', 800, 800, 12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "Z6bI37TrHSm0",
        "outputId": "53430c22-e6f6-4912-b81a-b22ef14b354c"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(max_features = 15,stop_words = 'english',ngram_range = (2,2)) # Top 15 terms\n",
        "x = vectorizer.fit_transform(test['dialogue'].fillna(''))\n",
        "df_tfidfvect = pd.DataFrame(x.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "plot_correlation(df_tfidfvect, 'Bigrams', 'Test - Dialogue', 800, 800, 12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "xlFtkw6VHWCB",
        "outputId": "083773df-9665-4d5b-ef76-091cd0904ec4"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(max_features = 15,stop_words = 'english',ngram_range = (2,2)) # Top 15 terms\n",
        "x = vectorizer.fit_transform(test['summary'].fillna(''))\n",
        "df_tfidfvect = pd.DataFrame(x.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "plot_correlation(df_tfidfvect, 'Bigrams', 'Test - Summary', 800, 800, 12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "UZxCBbpgHbWV",
        "outputId": "a74e6bd8-0368-47ff-9bcd-123a906f4480"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(max_features = 15,stop_words = 'english',ngram_range = (3,3)) # Top 15 terms\n",
        "x = vectorizer.fit_transform(test['dialogue'].fillna(''))\n",
        "df_tfidfvect = pd.DataFrame(x.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "plot_correlation(df_tfidfvect, 'Trigrams', 'Test - Dialogue', 800, 800, 12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "mdvu8Ds3HeEc",
        "outputId": "3d149b96-e44a-4a8c-da32-679f1f3501bc"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(max_features = 15,stop_words = 'english',ngram_range = (3,3)) # Top 15 terms\n",
        "x = vectorizer.fit_transform(test['summary'].fillna(''))\n",
        "df_tfidfvect = pd.DataFrame(x.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "plot_correlation(df_tfidfvect, 'Trigrams', 'Test - Summary', 800, 800, 12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ob4tXuFVHg6I",
        "outputId": "5b4af017-17b9-463b-f094-dc65f31b2137"
      },
      "outputs": [],
      "source": [
        "# Extracting info on the val dataset\n",
        "describe_df(val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrKIHJV4IpQ9"
      },
      "outputs": [],
      "source": [
        "# Removing 'Id' from categorical features list\n",
        "categorical_features.remove('id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d4PDw3cMIrKh",
        "outputId": "cec8e18a-7a10-4eeb-b54c-1f1f6fba505b"
      },
      "outputs": [],
      "source": [
        "df_text_lenght = pd.DataFrame()\n",
        "for feat in categorical_features:\n",
        "    df_text_lenght[feat] = val[feat].apply(lambda x: len(str(x).split()))\n",
        "\n",
        "histogram_boxplot(df_text_lenght,'#89c2e0', '#d500ff', 600, 1000, True, 'Validation Dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "4YtrcRQGIszq",
        "outputId": "ee540d36-01e1-4056-814c-9e752887649a"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(max_features = 15,stop_words = 'english') # Top 15 terms\n",
        "x = vectorizer.fit_transform(val['dialogue'].fillna(''))\n",
        "df_tfidfvect = pd.DataFrame(x.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "plot_correlation(df_tfidfvect, 'Unigrams', 'Validation - Dialogue', 800, 800, 12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "Ep8XefP5Iutu",
        "outputId": "1bd4883a-feee-468a-fab3-6e8d2302d632"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(max_features = 15,stop_words = 'english') # Top 15 terms\n",
        "x = vectorizer.fit_transform(val['summary'].fillna(''))\n",
        "df_tfidfvect = pd.DataFrame(x.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "plot_correlation(df_tfidfvect, 'Unigrams', 'Validation - Summary', 800, 800, 12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "HgjGrZwDIxAC",
        "outputId": "07527e58-217e-42a1-dceb-b2240223edda"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(max_features = 15,stop_words = 'english',ngram_range = (2,2)) # Top 15 terms\n",
        "x = vectorizer.fit_transform(val['dialogue'].fillna(''))\n",
        "df_tfidfvect = pd.DataFrame(x.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "plot_correlation(df_tfidfvect, 'Bigrams', 'Validation - Dialogue', 800, 800, 12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "gbIoVvNxIypB",
        "outputId": "06a5d3c0-4d41-4321-b94f-e7f320981869"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(max_features = 15,stop_words = 'english',ngram_range = (2,2)) # Top 15 terms\n",
        "x = vectorizer.fit_transform(val['dialogue'].fillna(''))\n",
        "df_tfidfvect = pd.DataFrame(x.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "plot_correlation(df_tfidfvect, 'Bigrams', 'Validation - Dialogue', 800, 800, 12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "QIxpa1y2I0TG",
        "outputId": "19969442-aa45-48b5-bba8-ef3d0c236934"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(max_features = 15,stop_words = 'english',ngram_range = (3,3)) # Top 15 terms\n",
        "x = vectorizer.fit_transform(val['dialogue'].fillna(''))\n",
        "df_tfidfvect = pd.DataFrame(x.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "plot_correlation(df_tfidfvect, 'Trigrams', 'Validation - Dialogue', 800, 800, 12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "EZRNOIauI25S",
        "outputId": "80e49b4e-785d-4a1f-f014-176890f53d70"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(max_features = 15,stop_words = 'english',ngram_range = (3,3)) # Top 15 terms\n",
        "x = vectorizer.fit_transform(val['summary'].fillna(''))\n",
        "df_tfidfvect = pd.DataFrame(x.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "plot_correlation(df_tfidfvect, 'Trigrams', 'Validation - Summary', 800, 800, 12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVSnMikhI412"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
